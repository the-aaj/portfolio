{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression on Housing Prices\n",
    "\n",
    "Using regression techniques to predict prices on houses in Ames, IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#Importing necessary modules\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing Metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "#Importing models and model selection\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv(\"train.csv\")\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that converts a certain type of string ordinal to a numeric ordinal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ordinal(row):\n",
    "    if row == \"Ex\":\n",
    "        return 5\n",
    "    elif row == \"Gd\":\n",
    "        return 4\n",
    "    elif row == \"TA\":\n",
    "        return 3\n",
    "    elif row == \"Fa\":\n",
    "        return 2\n",
    "    elif row == \"Po\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating some functions that will:\n",
    "- Transform the dataframe to remove non-applicable or ineffective features\n",
    "- Choose featuers that only have strong correlations to the sale price of a house\n",
    "- Generate an RMSE value based on the number of K folds selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that transforms features\n",
    "def transform_features(df, for_test=False, train_columns=[]):\n",
    "    tdf = df.copy()\n",
    "    \n",
    "    # Dropping the following columns:\n",
    "    ## Order = an index number that adds no value to regression\n",
    "    ## PID = A unique identifier that does not add value\n",
    "    ## Misc Val, Mo Sold, Yr Sold, Sale Type, and Sale Condition = columns that leak data\n",
    "    ## Garage Yr Blt = Ordinal column that does not add value to regression\n",
    "    ## Lot Shape,Utilities, Land Slope, BsmtFin Type 1,BsmtFin Type 1,\n",
    "    ##     Electrical,Functional,Garage Finish,Paved Drive, and Fence = Ordinal values using strings, too time consuming to convert \n",
    "    tdf = tdf.drop(columns=['Id','MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
    "           'SaleCondition','GarageYrBlt','LotShape','Utilities', 'LandSlope', \n",
    "           'BsmtFinType1','BsmtFinType1','Electrical','Functional',\n",
    "            'GarageFinish','PavedDrive','Fence'])\n",
    "    \n",
    "    # Trainforming the original string values to numeric ones\n",
    "    ord_transform = ['ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','GarageQual','GarageCond','PoolQC','HeatingQC','KitchenQual','FireplaceQu']\n",
    "    for o in ord_transform:\n",
    "        tdf[o] = tdf[o].apply(transform_ordinal)\n",
    "        \n",
    "    # Removing any columns that have more than 40% (used to be 25%) of its rows populated\n",
    "    # with null values (only if the dataframe passed in isn't for testing)\n",
    "    if for_test==False:\n",
    "        null_counts = tdf.isnull().sum()\n",
    "        null_cutoff = null_counts[(null_counts/tdf.shape[0]) < 0.40] \n",
    "        df_u25 = tdf[null_cutoff.index]\n",
    "    else:\n",
    "        df_u25 = tdf.copy()\n",
    "    \n",
    "    # Implementing one hot encoding for categorical variables\n",
    "    text_cols = df_u25.select_dtypes(include=['object']).columns\n",
    "    for col in text_cols:\n",
    "        dummy_cols = pd.get_dummies(df_u25[col], prefix=col)\n",
    "        df_u25 = pd.concat([df_u25,dummy_cols], axis=1)\n",
    "        df_u25.drop(columns=[col],inplace=True)\n",
    "        \n",
    "    # Getting a list of columns that have at most 10% (used to be 5%) of its rows populated\n",
    "    # with null values, as well as a second list for those columns with\n",
    "    # more than 5% \n",
    "    under_5_p_col = df_u25.isnull().sum()[((df_u25.isnull().sum()/df_u25.shape[0]) < .10\n",
    "                                       ) & ((df_u25.isnull().sum()/df_u25.shape[0]) > 0\n",
    "                                       )].index\n",
    "    over_5_p_col = df_u25.isnull().sum()[(df_u25.isnull().sum()/df_u25.shape[0]) >= .10].index\n",
    "    \n",
    "    # Replacing the null values with the column mode for \n",
    "    # columns that have at most 5% of its rows populated\n",
    "    # with null values\n",
    "    for c in under_5_p_col:\n",
    "        df_u25[c] = df_u25[c].fillna(df_u25[c].mode()[0]) \n",
    "\n",
    "    # Replacing the null values with the column mean for \n",
    "    # columns that have more than 5% of its rows populated\n",
    "    # with null values\n",
    "    for c in over_5_p_col:\n",
    "        df_u25[c] = df_u25[c].fillna(df_u25[c].mean())\n",
    "\n",
    "    # Adding a column that contains the difference between the year a house was remodeled and\n",
    "    # the year it was built, since age is a better regression factor than a year\n",
    "    df_u25['years_until_remod'] = df_u25['YearRemodAdd'] - df_u25['YearBuilt']\n",
    "\n",
    "    # Scaling the remaining columns using min max normalization\n",
    "    features = list(df_u25.columns)\n",
    "    if 'SalePrice' in features:\n",
    "        features.remove('SalePrice')\n",
    "    for c in features:\n",
    "        df_u25[c] = (df_u25[c] - df_u25[c].min()) / (df_u25[c].max() - df_u25[c].min())\n",
    "        \n",
    "    # Add any dummy columns that exist in the training set, but not in the test set\n",
    "    if for_test==True:\n",
    "        for tc in train_columns:\n",
    "            if tc not in df_u25.columns:\n",
    "                df_u25[tc] = 0\n",
    "                \n",
    "    return df_u25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that chooses the best set of features using SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature(df):\n",
    "    # Removing non-numeric columns or columns with null values\n",
    "    initial_cols = df.columns\n",
    "    for cols in initial_cols:\n",
    "        if (df[cols].dtype == 'object') or (df[cols].dtype.name == 'category') or (df[cols].isnull().sum() > 0):\n",
    "            df.drop(columns=cols, inplace=True)\n",
    "                \n",
    "    # Creating dataframes for features and target columns\n",
    "    all_X = df.copy()\n",
    "    all_X.drop(columns=['SalePrice'], inplace=True)\n",
    "    all_y = df['SalePrice']\n",
    "\n",
    "    # Instantiating an instance of a Gradient Boosting Regressor\n",
    "    gb = GradientBoostingRegressor()\n",
    "\n",
    "    # Using RFECV to attain the optimal set of features \n",
    "    selector = RFECV(gb)\n",
    "    #selector = SelectFromModel(rfr)\n",
    "    selector.fit(all_X,all_y)\n",
    "\n",
    "    # Returning the optimal feature set\n",
    "    optimized = all_X.columns[selector.get_support()]\n",
    "    print(\"The optimal feature set \")\n",
    "    print(optimized)\n",
    "    return optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to find the best model and hyperparameters via Random Search.  For the sake of brevity, only three types of algorithms are considered: Gradient Boosting Regressor, Random Forest Regressor, and K Neighbors Regressor.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_model_random(df, features):\n",
    "    # Creating dataframes for features and target columns\n",
    "    all_X = df[features]\n",
    "    all_y = df['SalePrice']\n",
    "    \n",
    "    # Creating a list of models with hyperparameters\n",
    "    models = [\n",
    "        {\n",
    "            \"name\": \"GradientBoostingRegressor\",\n",
    "            \"estimator\": GradientBoostingRegressor(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"n_estimators\": np.linspace(5,500,100,dtype='int'),\n",
    "                    \"subsample\": np.linspace(0.1,1,11),\n",
    "                    \"learning_rate\": [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "                    \"loss\": ['ls', 'lad', 'huber', 'quantile'],\n",
    "                    \"criterion\": [\"friedman_mse\",\"mse\", \"mae\"],\n",
    "                    \"max_depth\": np.linspace(2,11,10, dtype='int'),\n",
    "                    \"max_features\": [\"log2\",\"sqrt\",\"auto\"],\n",
    "                    \"min_samples_leaf\": np.linspace(1,10,10, dtype='int'),\n",
    "                    \"min_samples_split\": np.linspace(2,11,10, dtype='int')\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"KNeighborsRegressor\",\n",
    "            \"estimator\": KNeighborsRegressor(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"n_neighbors\": np.linspace(1,100,50, dtype=\"int\"),\n",
    "                    \"weights\": [\"distance\", \"uniform\"],\n",
    "                    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                    \"p\": [1,2]\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RandomForestRegressor\",\n",
    "            \"estimator\": RandomForestRegressor(),\n",
    "            \"hyperparameters\":\n",
    "                {         \n",
    "                    \"n_estimators\": np.linspace(5,500,100,dtype='int'),\n",
    "                    \"criterion\": [\"friedman_mse\",\"mse\", \"mae\"],\n",
    "                    \"max_depth\": np.linspace(2,11,10, dtype='int'),\n",
    "                    \"max_features\": [\"log2\",\"sqrt\",\"auto\"],\n",
    "                    \"min_samples_leaf\": np.linspace(1,10,10, dtype='int'),\n",
    "                    \"min_samples_split\": np.linspace(2,11,10, dtype='int')\n",
    "                }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Finding the best configuration for each type of model in the list above\n",
    "    for m in models:\n",
    "        print(m[\"name\"])\n",
    "        rand = RandomizedSearchCV(m['estimator'], param_distributions=m['hyperparameters'],n_iter = 25, cv=4, scoring='r2')\n",
    "        rand.fit(all_X,all_y)\n",
    "        m['best_params'] = rand.best_params_\n",
    "        m['best_score'] = rand.best_score_\n",
    "        m['best_estimator'] = rand.best_estimator_\n",
    "        print(\"Best set of parameters: \")\n",
    "        print(m['best_params'])\n",
    "        print(\"Best score:\")\n",
    "        print(m['best_score'])\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        \n",
    "    return models\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the functions are defined, the training data is run through each function to attain the optimal set of features, and then the optimal model (including hyperparameters).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = transform_features(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaen3.ELSYS\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal feature set \n",
      "Index(['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
      "       'YearRemodAdd', 'MasVnrArea', 'ExterQual', 'ExterCond', 'BsmtQual',\n",
      "       ...\n",
      "       'Heating_Wall', 'CentralAir_N', 'CentralAir_Y', 'GarageType_2Types',\n",
      "       'GarageType_Attchd', 'GarageType_Basment', 'GarageType_BuiltIn',\n",
      "       'GarageType_CarPort', 'GarageType_Detchd', 'years_until_remod'],\n",
      "      dtype='object', length=163)\n",
      "........\n"
     ]
    }
   ],
   "source": [
    "best_features = select_feature(training)\n",
    "print('........')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor\n",
      "Best set of parameters: \n",
      "{'subsample': 0.73, 'n_estimators': 395, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 8, 'loss': 'lad', 'learning_rate': 0.1, 'criterion': 'mse'}\n",
      "Best score:\n",
      "0.8847401787614582\n",
      "\n",
      "\n",
      "KNeighborsRegressor\n",
      "Best set of parameters: \n",
      "{'weights': 'distance', 'p': 1, 'n_neighbors': 9, 'algorithm': 'ball_tree'}\n",
      "Best score:\n",
      "0.7361411549108609\n",
      "\n",
      "\n",
      "RandomForestRegressor\n",
      "Best set of parameters: \n",
      "{'n_estimators': 155, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'friedman_mse'}\n",
      "Best score:\n",
      "0.8538967796461534\n",
      "\n",
      "\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "best_models = select_model_random(training,best_features)\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model and features\n",
    "\n",
    "Once the features and models are selected, they will be used to attempt predicting housing prices from a test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the test data\n",
    "holdout = pd.read_csv(\"test.csv\")\n",
    "train_columns = training.columns\n",
    "ids = holdout['Id']\n",
    "holdout = transform_features(holdout, True, train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id      SalePrice\n",
      "0   1461  139068.401339\n",
      "1   1462  162781.113521\n",
      "2   1463  194768.071781\n",
      "3   1464  190327.682474\n",
      "4   1465  201901.567461\n",
      "5   1466  191994.439161\n",
      "6   1467  182035.050176\n",
      "7   1468  185146.280245\n",
      "8   1469  197242.497533\n",
      "9   1470  139214.931936\n",
      "10  1471  223724.134298\n",
      "11  1472  106200.265665\n",
      "12  1473  108398.746791\n",
      "13  1474  150429.203614\n",
      "14  1475  133243.809046\n",
      "15  1476  338420.016595\n",
      "16  1477  251189.782705\n",
      "17  1478  302354.496851\n",
      "18  1479  308345.220491\n",
      "19  1480  381217.164759\n"
     ]
    }
   ],
   "source": [
    "# Creating a function that generates a CSV file for submission to Kaggle for results.\n",
    "\n",
    "def save_submission_file(model, features, filename='submission.csv'):\n",
    "    holdout_predictions = model['best_estimator'].predict(holdout[features])\n",
    "    submission_df = {\"Id\": ids, \"SalePrice\": holdout_predictions}\n",
    "    submission = pd.DataFrame(submission_df)\n",
    "    print(submission.head(20))\n",
    "    submission.to_csv(filename,index=False)\n",
    "    \n",
    "save_submission_file(best_models[2],best_features,'submission_four.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
